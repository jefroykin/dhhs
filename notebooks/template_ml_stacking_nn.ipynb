{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import multiprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors \n",
    "\n",
    "DFS_PATH = '../data/training_set.csv'\n",
    "\n",
    "SIZE = 100\n",
    "WINDOW = 10\n",
    "MIN_COUNT = 1\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DFS_PATH)\n",
    "print(len(df))\n",
    "df = df[['content','label']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_vectors_mean(corpus, model, size):\n",
    "    result = []\n",
    "\n",
    "    for sent in corpus:\n",
    "        s = []\n",
    "        for w in sent:\n",
    "            try:\n",
    "                s.append(model[w])\n",
    "            except KeyError:\n",
    "                s.append(np.zeros(size))\n",
    "\n",
    "        result.append(np.mean(s, axis=0))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_w2v_corpus(df):\n",
    "    r = []\n",
    "    for i in range(len(df)):\n",
    "        r.append(gensim.utils.simple_preprocess(df[i]))\n",
    "    return r\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r'[,!@#$%^&*)(|/><\";:.?\\'\\\\}{]',\"\",text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], \n",
    "                                                    df['vote'], \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepMoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmoji.model_def import deepmoji_emojis\n",
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    VOCAB = json.load(f)\n",
    "\n",
    "MAXLEN=30\n",
    "\n",
    "st = SentenceTokenizer(VOCAB, MAXLEN)\n",
    "model = deepmoji_emojis(MAXLEN, PRETRAINED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized, _, _ = st.tokenize_sentences(training['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_emojis = model.predict(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['deepmoji'] = list(predictions_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized, _, _ = st.tokenize_sentences(testing['content'])\n",
    "predictions_emojis = model.predict(tokenized)\n",
    "test_deepmoji = list(predictions_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['clean_text'] = [clean_text(text) for text in training['content'].values]\n",
    "testing['clean_text'] = [clean_text(text) for text in testing['content'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['content'] = read_w2v_corpus(training['content'])\n",
    "X_test = read_w2v_corpus(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(training['content'], \n",
    "                 size=SIZE, \n",
    "                 window=WINDOW,\n",
    "                 min_count=MIN_COUNT,\n",
    "                 workers=cores)\n",
    "\n",
    "model.train(training['content'], total_examples=model.corpus_count, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['w2v'] = transform_vectors_mean(training['content'], model, SIZE)\n",
    "X_test = transform_vectors_mean(X_test, model, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(training)):\n",
    "    try:\n",
    "        if len(training['w2v'][i]) == 0:\n",
    "            print('youpi')\n",
    "    except:\n",
    "        t.append(i)\n",
    "        \n",
    "training = training.drop(t).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training['w2v']\n",
    "train_label = training['vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_jobs=-1, max_iter=1000, tol=1e-4, n_iter=None)\n",
    "model_calibrated = CalibratedClassifierCV(base_estimator=clf, cv=3, method='sigmoid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_calibrated.fit(list(train), train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_calibrated.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Deepmojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=250, n_jobs=-1, class_weight='balanced')\n",
    "clf.fit(list(training['deepmoji'].values), train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_deepmoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Deepmojis and W2V Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [np.concatenate((train[i], training['deepmoji'][i]), axis=None)\n",
    "                  for i in range(len(train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = [np.concatenate((X_test[i], test_deepmoji[i]), axis=None)\n",
    "                  for i in range(len(test_deepmoji))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification text + Deepmojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_jobs=-1, max_iter=1000, tol=1e-4, n_iter=None)\n",
    "model_calibrated = CalibratedClassifierCV(base_estimator=clf, cv=3, method='sigmoid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_calibrated.fit(list(train_features), train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_calibrated.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification text TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_column(X):\n",
    "    return list(X['clean_text'].values)\n",
    "\n",
    "clf = linear_model.SGDClassifier(n_jobs=-1, max_iter=1000, tol=1e-4, n_iter=None)\n",
    "model_calibrated = CalibratedClassifierCV(base_estimator=clf, cv=3, method='sigmoid')\n",
    "\n",
    "tfidf_model = make_pipeline(FunctionTransformer(content_column, validate=False),\n",
    "                      TfidfVectorizer(min_df=0., max_df=1., use_idf=True, max_features=20000),\n",
    "                      model_calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.fit(training, training['vote'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tfidf_model.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification text LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=10, \n",
    "                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_jobs=-1, max_iter=1000, tol=1e-4, n_iter=None)\n",
    "model_calibrated = CalibratedClassifierCV(base_estimator=clf, cv=3, method='sigmoid')\n",
    "\n",
    "lsa_model = make_pipeline(FunctionTransformer(content_column, validate=False),\n",
    "                      TfidfVectorizer(min_df=0., max_df=1., use_idf=True, max_features=20000),\n",
    "                      svd_model,\n",
    "                      model_calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model.fit(training, training['vote'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lsa_model.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepmoji_column(X):\n",
    "    return list(X['deepmoji'].values)\n",
    "\n",
    "def w2v_feature(X):\n",
    "    return list(X['w2v'].values)\n",
    "\n",
    "def content_column(X):\n",
    "    return list(X['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['w2v'] = X_test\n",
    "testing['deepmoji'] = test_deepmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_jobs=-1, max_iter=1000, tol=1e-4, n_iter=None)\n",
    "model_calibrated = CalibratedClassifierCV(base_estimator=clf, cv=3, method='sigmoid')\n",
    "\n",
    "pipe1 = make_pipeline(FunctionTransformer(deepmoji_column, validate=False),\n",
    "                      RandomForestClassifier(n_estimators=250, n_jobs=-1))\n",
    "\n",
    "pipe2 = make_pipeline(FunctionTransformer(w2v_feature, validate=False),\n",
    "                      RandomForestClassifier(n_estimators=500, n_jobs=-1))\n",
    "\n",
    "pipe3 = make_pipeline(FunctionTransformer(w2v_feature, validate=False),\n",
    "                      model_calibrated)\n",
    "\n",
    "pipe4 = make_pipeline(FunctionTransformer(w2v_feature, validate=False), \n",
    "                      GaussianNB())\n",
    "\n",
    "tfidf_model = make_pipeline(FunctionTransformer(content_column, validate=False),\n",
    "                      TfidfVectorizer(min_df=0., max_df=1., use_idf=True, max_features=20000),\n",
    "                      model_calibrated)\n",
    "\n",
    "lsa_model = make_pipeline(FunctionTransformer(content_column, validate=False),\n",
    "                      TfidfVectorizer(min_df=0., max_df=1., use_idf=True, max_features=20000),\n",
    "                      svd_model,\n",
    "                      model_calibrated)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, lsa_model, tfidf_model],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=RandomForestClassifier(n_estimators=50, n_jobs=-1, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf.fit(training, training['vote'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sclf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(testing['vote'].values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import (\n",
    "    Input, Dense, Flatten, LSTM, Conv1D, MaxPooling1D, GlobalMaxPool1D, \n",
    "    Embedding, Bidirectional, GlobalMaxPooling1D, Dropout\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.initializers import Constant\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DFS_PATH)\n",
    "print(len(df))\n",
    "df = df[['content','label']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], \n",
    "                                                    df['vote'], \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, \n",
    "                                                y_test, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df=0., max_df=1., use_idf=True, max_features=20000)\n",
    "norm_corpus_matrix_train = tf.fit_transform(X_train['content'])\n",
    "norm_corpus_matrix_val   = tf.transform(X_val['content'])\n",
    "norm_corpus_matrix_test  = tf.transform(X_test['content'])\n",
    "\n",
    "norm_corpus_matrix_train = norm_corpus_matrix_train.toarray()\n",
    "norm_corpus_matrix_val = norm_corpus_matrix_val.toarray()\n",
    "norm_corpus_matrix_test = norm_corpus_matrix_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "d1 = Dense(100)(sequence_input)\n",
    "d2 = Dense(50)(d1)\n",
    "preds = Dense(labels.shape[1], activation='softmax')(d2)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model_summary = model.summary()\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = []\n",
    "model.summary(print_fn=lambda x: model_summary.append(x + '\\n'))\n",
    "model_summary = ' '.join(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"models/nn.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(norm_corpus_matrix_train,\n",
    "          y_train,\n",
    "          batch_size=1024,\n",
    "          epochs=20,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(norm_corpus_matrix_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "score = model.evaluate(norm_corpus_matrix_test, y_test, batch_size=1024)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
